{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ov-n3_9cIluF",
    "outputId": "3b515482-0731-45bd-8c34-e00ffdec09e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-surprise\n",
      "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anura\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\anura\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-surprise) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\anura\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-surprise) (1.14.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'error'\n",
      "Failed to build scikit-surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for scikit-surprise (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [115 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\dump.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\reader.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\utils.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      running egg_info\n",
      "      writing scikit_surprise.egg-info\\PKG-INFO\n",
      "      writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "      writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "      writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "      writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no previously-included files matching '*.so' found under directory 'surprise'\n",
      "      adding license file 'LICENSE.md'\n",
      "      writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\anura\\AppData\\Local\\Temp\\pip-build-env-yz0rgv7z\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'surprise.prediction_algorithms' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'surprise.prediction_algorithms' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'surprise.prediction_algorithms' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'surprise.prediction_algorithms' to be distributed and are\n",
      "              already explicitly excluding 'surprise.prediction_algorithms' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      running build_ext\n",
      "      building 'surprise.similarities' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (scikit-surprise)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "js2xTP-7ITqP",
    "outputId": "759778e0-6f50-4a95-aa3e-dc9e5bb47f27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "5         1080   49  Not for the very petite   \n",
       "6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "5  I love tracy reese dresses, but this one is no...       2                0   \n",
       "6  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  \n",
       "5                        4         General         Dresses    Dresses  \n",
       "6                        1  General Petite            Tops      Knits  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset (you would typically use pd.read_csv to load a CSV file,\n",
    "# but since you provided it in text form, we'll assume it's already loaded into a DataFrame).\n",
    "\n",
    "# Example DataFrame\n",
    "data = pd.read_csv(r'C:\\Users\\anura\\Downloads\\RS DATASET\\RS Practical 5\\Womens Clothing E-Commerce Reviews.csv')\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQ_CS3AeimC5",
    "outputId": "53f60b19-93fb-4e80-adf7-f6d15489dbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Total Error: 3.3029\n",
      "Epoch 10, Total Error: 0.8344\n",
      "Epoch 20, Total Error: 0.7806\n",
      "Epoch 30, Total Error: 0.7582\n",
      "Epoch 40, Total Error: 0.7451\n",
      "Epoch 50, Total Error: 0.7367\n",
      "Epoch 60, Total Error: 0.7311\n",
      "Epoch 70, Total Error: 0.7272\n",
      "Epoch 80, Total Error: 0.7242\n",
      "Epoch 90, Total Error: 0.7220\n",
      "\n",
      "Predicted User-Item Matrix:\n",
      "[[4.20630769 4.65338807 4.38261797 ... 4.75983752 3.84954596 3.91971399]\n",
      " [4.13857474 4.63618441 4.81592329 ... 4.45747263 4.03503162 3.82858239]\n",
      " [3.88145727 4.4048747  5.01182334 ... 3.95875665 4.02750946 3.56319829]\n",
      " ...\n",
      " [4.56444603 5.03973472 4.66972739 ... 5.20364816 4.13505063 4.25823435]\n",
      " [4.52785735 5.06512138 5.20649497 ... 4.90471494 4.38391605 4.19217701]\n",
      " [4.82638625 5.32730726 4.92336779 ... 5.50869483 4.36530538 4.5033993 ]]\n",
      "\n",
      "Top recommendations for User 0 (Age 60): Clothing Item IDs [1176  118]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Create a user-item interaction matrix\n",
    "# We will assume each user is uniquely represented by their 'Age' and Clothing ID as items.\n",
    "\n",
    "# Assign each unique clothing item to a column\n",
    "clothing_items = df['Clothing ID'].unique()\n",
    "users = df['Age'].unique()\n",
    "\n",
    "# Create a mapping from clothing items to indices\n",
    "item_index = {item: idx for idx, item in enumerate(clothing_items)}\n",
    "user_index = {user: idx for idx, user in enumerate(users)}\n",
    "\n",
    "# Initialize the user-item interaction matrix (ratings matrix)\n",
    "user_item_matrix = np.zeros((len(users), len(clothing_items)))\n",
    "\n",
    "# Populate the user-item matrix with ratings\n",
    "for _, row in df.iterrows():\n",
    "    user_idx = user_index[row['Age']]\n",
    "    item_idx = item_index[row['Clothing ID']]\n",
    "    user_item_matrix[user_idx, item_idx] = row['Rating']\n",
    "\n",
    "# Step 3: Matrix factorization using gradient descent\n",
    "num_users, num_items = user_item_matrix.shape\n",
    "num_factors = 2  # Latent factors\n",
    "alpha = 0.01     # Learning rate\n",
    "num_epochs = 100\n",
    "lambda_reg = 0.02  # Regularization parameter\n",
    "\n",
    "# Initialize user and item latent factor matrices with random values\n",
    "user_factors = np.random.rand(num_users, num_factors)\n",
    "item_factors = np.random.rand(num_items, num_factors)\n",
    "\n",
    "# Step 4: Perform matrix factorization using Gradient Descent\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_items):\n",
    "            if user_item_matrix[i, j] > 0:  # Only update for existing ratings\n",
    "                # Calculate the prediction error for user i and item j\n",
    "                prediction = np.dot(user_factors[i, :], item_factors[j, :].T)\n",
    "                error = user_item_matrix[i, j] - prediction\n",
    "\n",
    "                # Update user and item latent factors\n",
    "                user_factors[i, :] += alpha * (error * item_factors[j, :] - lambda_reg * user_factors[i, :])\n",
    "                item_factors[j, :] += alpha * (error * user_factors[i, :] - lambda_reg * item_factors[j, :])\n",
    "\n",
    "    # Calculate the total error every 1000 epochs for monitoring\n",
    "    if epoch % 10 == 0:\n",
    "        total_error = 0\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_items):\n",
    "                if user_item_matrix[i, j] > 0:\n",
    "                    prediction = np.dot(user_factors[i, :], item_factors[j, :].T)\n",
    "                    total_error += (user_item_matrix[i, j] - prediction) ** 2\n",
    "        print(f\"Epoch {epoch}, Total Error: {total_error/10000:.4f}\")\n",
    "\n",
    "# Step 5: Predict missing values for recommendations\n",
    "predicted_matrix = np.dot(user_factors, item_factors.T)\n",
    "print(\"\\nPredicted User-Item Matrix:\")\n",
    "print(predicted_matrix)\n",
    "\n",
    "# Step 6: Recommend items for a specific user\n",
    "user_id = 0  # Example user\n",
    "# Recommend top 2 items that user hasn't interacted with\n",
    "user_ratings = user_item_matrix[user_id]\n",
    "predicted_ratings = predicted_matrix[user_id]\n",
    "recommendations = np.argsort(predicted_ratings - user_ratings)  # Sort by predicted rating\n",
    "\n",
    "# Only recommend items not yet interacted with\n",
    "recommended_items = [i for i in recommendations if user_ratings[i] == 0][:2]\n",
    "print(f\"\\nTop recommendations for User {user_id} (Age {users[user_id]}): Clothing Item IDs {clothing_items[recommended_items]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NG6Tm2XVIXML",
    "outputId": "7375dd3f-160e-4610-cd4a-22cf2b574a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 4.156795365039826\n",
      "Top Recommendations for User 5: [(np.int64(1078), np.float64(2.847168166262219e-09)), (np.int64(868), np.float64(1.2776029522272406e-11)), (np.int64(1077), np.float64(6.03820272475959e-12))]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'data' is your original dataframe\n",
    "df = data.copy()\n",
    "\n",
    "# Step 1: Adjust index to start from 2 and create the 'user_id' column\n",
    "df['user_id'] = df.index  # Use the current index as the user_id\n",
    "df['user_id'] = df['user_id'] + 2  # Adjust index so it starts from 2\n",
    "\n",
    "# Step 2: Create the user-item interaction matrix (pivot table)\n",
    "# Using 'user_id' for the index and 'Clothing ID' for the columns\n",
    "interaction_matrix = df.pivot_table(index='user_id', columns='Clothing ID', values='Rating', fill_value=0)\n",
    "\n",
    "# Step 3: Apply SVD (Singular Value Decomposition) - Matrix factorization technique\n",
    "svd = TruncatedSVD(n_components=2)  # Use 2 components, adjust for better performance if needed\n",
    "latent_matrix = svd.fit_transform(interaction_matrix)\n",
    "\n",
    "# Step 4: Reconstruct the approximation of the original matrix\n",
    "approx_matrix = np.dot(latent_matrix, svd.components_)\n",
    "\n",
    "# Step 5: Calculate RMSE (Root Mean Square Error) for prediction accuracy\n",
    "# We need to compare the predicted values with actual ratings\n",
    "# Flatten both the original and approximated matrices for comparison\n",
    "original_matrix_flat = interaction_matrix.values.flatten()\n",
    "approx_matrix_flat = approx_matrix.flatten()\n",
    "\n",
    "# Mask the zero entries in the interaction matrix (because they represent missing values)\n",
    "mask = original_matrix_flat != 0\n",
    "rmse = np.sqrt(mean_squared_error(original_matrix_flat[mask], approx_matrix_flat[mask]))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "\n",
    "# Step 6: Making Recommendations for a specific user\n",
    "user_id = 5  # Example user, can be any user_id from your dataset\n",
    "if user_id not in interaction_matrix.index:\n",
    "    print(f\"User {user_id} not found.\")\n",
    "else:\n",
    "    user_row_index = interaction_matrix.index.get_loc(user_id)  # Find the row index for the user\n",
    "\n",
    "    # Predict the ratings for items the user hasn't rated yet\n",
    "    unrated_items = interaction_matrix.iloc[user_row_index] == 0  # Find unrated items\n",
    "    predicted_ratings = approx_matrix[user_row_index]\n",
    "\n",
    "    # Get predictions for unrated items\n",
    "    recommendations = []\n",
    "    for i, unrated in enumerate(unrated_items):\n",
    "        if unrated:  # If the item is unrated\n",
    "            recommendations.append((interaction_matrix.columns[i], predicted_ratings[i]))\n",
    "\n",
    "    # Sort by predicted rating and recommend the top items\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recommendations = recommendations[:3]  # Top 3 recommendations\n",
    "    print(f\"Top Recommendations for User {user_id}: {top_recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gT9vatwUIkls"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
